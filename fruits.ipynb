{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fruit recognition using Fuzzy logic\n",
    "## (using sci-kit decision tree classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import mahotas as mt\n",
    "\n",
    "fixed_size       = tuple((80, 80))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shape extraction (Hu moments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature-descriptor-1: Hu Moments\n",
    "def fd_hu_moments(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n",
    "    \n",
    "    feature = np.mean(feature)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haralick Texture Feature Vector Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature-descriptor-2: Haralick Texture\n",
    "def fd_haralick(image):\n",
    "    # convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # compute the haralick texture feature vector\n",
    "    haralick = mt.features.haralick(gray).mean(axis=0)\n",
    "    \n",
    "    # return the result\n",
    "    haralick = np.mean(haralick)\n",
    "    return haralick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature-descriptor-3: Color Histogram\n",
    "def fd_histogram(image, mask=None):\n",
    "    # grab the image channels, initialize the tuple of colors,\n",
    "    # the figure and the flattened feature vector\n",
    "    chans = cv2.split(image)\n",
    "    colors = (\"b\", \"g\", \"r\")\n",
    "\n",
    "    # loop over the image channels\n",
    "    for (chan, color) in zip(chans, colors):\n",
    "        # create a histogram for the current channel and\n",
    "        # concatenate the resulting histograms for each\n",
    "        # channel\n",
    "        hist = cv2.calcHist([chan], [0], None, [256], [0, 256])\n",
    "    hist = np.mean(hist)\n",
    "#     print(hist)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing all Images using Haralic Texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"D:\\python\\opencv\\dataset\\preprocessedData\" # Note: Add your dataset path . \n",
    "CATEGORIES = [ \"apple\", \"banana\",\"mixed\",\"orange\"] # Create directories based on the category .  \n",
    "\n",
    "# training the data\n",
    "# by creating multidim array and appending all individual img's gray-scale value.\n",
    "# empty list to hold feature vectors and train labels\n",
    "\n",
    "\n",
    "train_features = []\n",
    "train_labels = []\n",
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(datadir, category)    #path for diff classes.\n",
    "        \n",
    "        class_num = CATEGORIES.index(category)   # assigning numbers to diff classes. \n",
    "        for img in os.listdir(path):\n",
    "            # exception is used to pass broken images.\n",
    "            try:\n",
    "                image = cv2.imread(os.path.join(path,img))\n",
    "\n",
    "                # convert the image to grayscale\n",
    "#                 gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # extract haralick texture from the image\n",
    "                feature1 = fd_hu_moments(image)\n",
    "                feature2 = fd_haralick(image)\n",
    "                feature3 = fd_histogram(image)\n",
    "#                 features = np.mean(features)     #extra\n",
    "\n",
    "                # append the feature vector and label\n",
    "                training_data.append([[feature1, feature2, feature3], class_num])\n",
    "                \n",
    "            except Exception as e:\n",
    "                pass\n",
    "            \n",
    "create_training_data()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))\n",
    "# print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data is organised according to classes.\n",
    "# to include all classes during training the data should be randomized\n",
    "# So that 75% of training data cover all classes of FLOWERS.\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00012010933678206954, 795.651224046627, 1665.625]\n",
      "2\n",
      "[0.00013773628551780128, 1826.0246102793765, 937.2656]\n",
      "0\n",
      "[0.00024203208654577883, 1337.3808539836405, 2765.625]\n",
      "0\n",
      "[0.00012743320159033425, 133.25810735254225, 21824.0]\n",
      "1\n",
      "[0.00011493205279988547, 839.8680407755453, 478.51562]\n",
      "3\n",
      "[0.00017967310007190024, 1620.535722188505, 4265.0]\n",
      "3\n",
      "[0.00013583043087315996, 2021.8475848742517, 4882.9688]\n",
      "0\n",
      "[0.00021856547613250733, 3467.5372142633496, 46211.895]\n",
      "1\n",
      "[0.00016120930982631908, 2920.992697446246, 940.625]\n",
      "3\n",
      "[0.00012182767331041552, 775.1245931536098, 4859.7656]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# to check whether data is randomized. \n",
    "for check in training_data[:10]:\n",
    "    print(check[0])    # img matrix\n",
    "    print(check[1])    # img class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00012010933678206954, 795.651224046627, 1665.625]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for features, label in training_data:\n",
    "    train_features.append(features)\n",
    "    train_labels.append(label)\n",
    "    \n",
    "print(train_features[0])         #for 1st image.\n",
    "print(train_labels[0])\n",
    "# print(X[0][0])                 #for 1st image 1st row.\n",
    "# print(X)                       #for whole set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data using Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.tree as tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(train_features,train_labels,test_size=0.25,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train).reshape(-1, 3)      #extra\n",
    "\n",
    "decision_tree_classifier=DecisionTreeClassifier()\n",
    "dtree = decision_tree_classifier.fit(X_train,y_train)\n",
    "print(dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'decision_tree.png'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = [\"shape\",\"texture\",\"color\"]\n",
    "tn = [\"apple\",\"banana\",\"mixed\",\"orange\"]\n",
    "\n",
    "dot = tree.export_graphviz(dtree, out_file=None, feature_names=fn, class_names=tn, filled=True, rounded=True, special_characters=True)\n",
    " \n",
    "graph = graphviz.Source(dot)\n",
    "graph.format = 'png'\n",
    "graph.render('decision_tree', view=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4915254237288136"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array(X_test).reshape(-1, 3)      #extra\n",
    "\n",
    "decision_tree_classifier.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit = [\"apple\",\"banana\",\"mixed\",\"orange\"] \n",
    "sample = \"D:\\python\\opencv\\dataset\\preprocessedData\\orange\\orange_5.jpg\" # Take a test sample from any one of the directories\n",
    "image = cv2.imread(sample)\n",
    "\n",
    "feature1 = fd_hu_moments(image)\n",
    "feature2 = fd_haralick(image)\n",
    "feature3 = fd_histogram(image)\n",
    "fts = [feature1, feature2, feature3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fruit is :\n",
      "orange\n"
     ]
    }
   ],
   "source": [
    "#features = np.array(features).reshape(-1, 13)\n",
    "features = np.array(fts).reshape(-1, 3)          #extra\n",
    "\n",
    "prediction = dtree.predict(features)\n",
    "print(\"The fruit is :\")\n",
    "print(fruit[prediction[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
